// Signature file for parser generated by fsyacc
module UBViews.QueryEngine.Parser
type token = 
  | EOF
  | FILTERBY
  | TOPID
  | DOCID
  | SEQID
  | PARID
  | SECID
  | FILTERID of (string)
  | AND
  | OR
  | TILDE
  | QUOTATION_MARK
  | LEFT_PAREN
  | RIGHT_PAREN
  | LEFT_BRACKET
  | RIGHT_BRACKET
  | STERM of (string)
  | TERM of (string)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_FILTERBY
    | TOKEN_TOPID
    | TOKEN_DOCID
    | TOKEN_SEQID
    | TOKEN_PARID
    | TOKEN_SECID
    | TOKEN_FILTERID
    | TOKEN_AND
    | TOKEN_OR
    | TOKEN_TILDE
    | TOKEN_QUOTATION_MARK
    | TOKEN_LEFT_PAREN
    | TOKEN_RIGHT_PAREN
    | TOKEN_LEFT_BRACKET
    | TOKEN_RIGHT_BRACKET
    | TOKEN_STERM
    | TOKEN_TERM
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_UserQuery
    | NONTERM_SingleQuery
    | NONTERM_FilterId
    | NONTERM_Phrase
    | NONTERM_CTerm
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> (Ast.Query list) 
